{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "693b2d0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "\n",
    "data_path = \"faces/\"\n",
    "onlyfiles = [f for f in listdir(data_path) if isfile(join(data_path, f))]\n",
    "\n",
    "Training_data, Labels = [], []\n",
    "for i, files in enumerate(onlyfiles):\n",
    "    image_path = data_path + onlyfiles[i]\n",
    "    images = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "    Training_data.append(np.asarray(images, dtype=np.uint8))\n",
    "    Labels.append(i)\n",
    "Labels = np.asarray(Labels, dtype=np.int32)\n",
    "model = cv2.face.LBPHFaceRecognizer_create()\n",
    "model.train(np.asarray(Training_data), np.asarray(Labels))\n",
    "print(\"model traind\")\n",
    "\n",
    "face_classifier = cv2.CascadeClassifier(\n",
    "    \"haarcascades/haarcascade_frontalface_default.xml\"\n",
    ")\n",
    "\n",
    "\n",
    "def face_detector(img, size=0.5):\n",
    "    grey = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    faces = face_classifier.detectMultiScale(grey, 1.3, 3)\n",
    "    if faces is ():\n",
    "        return img, []\n",
    "\n",
    "    for x, y, w, h in faces:\n",
    "        cv2.rectangle(img, (x, y), (x + w, y + h), (0, 255, 255), 2)\n",
    "        roi = img[y : y + h, x : x + w]\n",
    "        roi = cv2.resize(roi, (200, 200))\n",
    "\n",
    "    return img, roi\n",
    "\n",
    "\n",
    "url = \"http://172.20.10.6:8080\"\n",
    "cap = cv2.VideoCapture(0)\n",
    "# cap = cv2.VideoCapture(url + '/video')\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    img, face = face_detector(frame)\n",
    "    # print(img)\n",
    "    print(face)\n",
    "    try:\n",
    "        face = cv2.cvtColor(face, cv2.COLOR_BGR2GRAY)\n",
    "        result = model.predict(face)\n",
    "        if result[1] < 500:\n",
    "            confidence = int(100 * (1 - (result[1]) / 300))\n",
    "            display_string = str(confidence) + \"% confidence\"\n",
    "        cv2.putText(\n",
    "            img,\n",
    "            display_string,\n",
    "            (110, 120),\n",
    "            cv2.FONT_HERSHEY_COMPLEX,\n",
    "            1,\n",
    "            (250, 120, 255),\n",
    "        )\n",
    "\n",
    "        if confidence > 75:\n",
    "            cv2.putText(\n",
    "                img, \"Unlocked\", (250, 450), cv2.FONT_HERSHEY_COMPLEX, 1, (0, 255, 0)\n",
    "            )\n",
    "            cv2.imshow(\"Face Cropper\", img)\n",
    "        else:\n",
    "            cv2.putText(\n",
    "                img, \"locked\", (250, 450), cv2.FONT_HERSHEY_COMPLEX, 1, (0, 0, 255)\n",
    "            )\n",
    "            cv2.imshow(\"Face Cropper\", img)\n",
    "\n",
    "    except:\n",
    "        cv2.putText(\n",
    "            img, \"No Face\", (250, 450), cv2.FONT_HERSHEY_COMPLEX, 1, (0, 0, 255)\n",
    "        )\n",
    "        cv2.imshow(\"Face Cropper\", img)\n",
    "        pass\n",
    "\n",
    "    if cv2.waitKey(1) == 13:\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cce284c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"The provided code utilizes the cv2 (OpenCV) library in Python for face recognition. Here is a detailed description\n",
    "of the code:\n",
    "\n",
    "Importing the necessary modules:\n",
    "\n",
    "The code imports cv2 for computer vision tasks and numpy for array manipulation.\n",
    "It also imports modules from the standard library: listdir and isfile from the os module.\n",
    "Setting up file paths and variables:\n",
    "\n",
    "The variable data_path stores the path to the directory containing face images.\n",
    "The onlyfiles list is populated with filenames of image files in the data_path directory.\n",
    "Preparing training data:\n",
    "\n",
    "The Training_data and Labels lists are initialized to store the face images and corresponding labels, respectively.\n",
    "The code loops through the files and reads each image using cv2.imread().\n",
    "The image is converted to grayscale using cv2.IMREAD_GRAYSCALE and appended to Training_data.\n",
    "The label (index of the file) is appended to Labels.\n",
    "Finally, the Labels list is converted to a NumPy array of integer type.\n",
    "Training the model:\n",
    "\n",
    "An instance of the cv2.face.LBPHFaceRecognizer model is created.\n",
    "The model is trained using the face images in Training_data and their respective labels in Labels.\n",
    "Defining the face detector:\n",
    "\n",
    "The code defines a function called face_detector that takes an image and a size parameter.\n",
    "The image is converted to grayscale.\n",
    "The face_classifier cascade classifier is used to detect faces in the grayscale image.\n",
    "Detected faces are drawn with rectangles on the image, and a region of interest (ROI) is extracted around each face.\n",
    "The ROI is resized to a fixed dimension (200x200).\n",
    "The function returns the modified image and the extracted ROI.\n",
    "Capturing and processing video frames:\n",
    "\n",
    "The code initializes a video capture object using either the webcam (cv2.VideoCapture(0)) or an IP camera stream.\n",
    "The code enters a loop to continuously read frames from the video feed.\n",
    "Each frame is passed to the face_detector function to detect faces and obtain the ROI.\n",
    "The ROI is converted to grayscale and passed to the trained model for prediction.\n",
    "The confidence level of the prediction is calculated and displayed on the frame.\n",
    "Depending on the confidence level, the frame is annotated with \"Unlocked\" or \"Locked\" text indicating face recognition \n",
    "success or failure, respectively.\n",
    "The annotated frame is displayed using cv2.imshow().\n",
    "The loop continues until the user presses the Enter key.\n",
    "Releasing resources:\n",
    "\n",
    "Once the loop is terminated, the video capture object is released using cap.release().\n",
    "All windows created by OpenCV are closed using cv2.destroyAllWindows().\n",
    "This code provides a basic face recognition system that detects faces in video frames, compares them to a trained model, \n",
    "and displays the result in real-time. You can customize the code to suit your specific needs, such as using a different\n",
    "face recognition algorithm or integrating it with other applications.\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
